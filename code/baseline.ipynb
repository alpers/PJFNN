{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "- TF-IDF vectors to represent the texts.\n",
    "- Use several machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:39:44.167236Z",
     "start_time": "2024-11-24T18:39:43.291247Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:39:48.505412Z",
     "start_time": "2024-11-24T18:39:46.593499Z"
    }
   },
   "source": [
    "user_set = pd.read_csv(\"user_set.csv\")\n",
    "job_set = pd.read_csv(\"job_set_cleaned.csv\")\n",
    "work_history = pd.read_csv(\"work_history.csv\")\n",
    "dataset = pd.read_csv(\"dataset.csv\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TF-IDF vectors for text representation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:40:16.467104Z",
     "start_time": "2024-11-24T18:39:49.514965Z"
    }
   },
   "source": [
    "# about 1 min\n",
    "job_set = job_set.fillna(\" \")\n",
    "job_set[\"word\"] = job_set.Title + job_set.Description + job_set.Requirements\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=5, max_features=100, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(job_set['word'])"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Filter out users with more than 10 applications"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:40:20.791528Z",
     "start_time": "2024-11-24T18:40:20.754646Z"
    }
   },
   "source": [
    "temp = sorted(dict(dataset.UserID.value_counts()).items(), key=lambda x: x[1], reverse=True)\n",
    "exclude_user_id = [i[0] for i in temp if i [1]>=10]\n",
    "len(exclude_user_id)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:40:22.283581Z",
     "start_time": "2024-11-24T18:40:22.278090Z"
    }
   },
   "source": [
    "dataset = dataset[~dataset.UserID.isin(exclude_user_id)]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select data in ```work_history,user_set```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:40:24.083977Z",
     "start_time": "2024-11-24T18:40:24.072431Z"
    }
   },
   "source": [
    "user_id = dataset.UserID.unique()\n",
    "work_history = work_history[work_history.UserID.isin(user_id)]\n",
    "user_set = user_set[user_set.UserID.isin(user_id)]\n",
    "user_set.reset_index(drop=True, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop duplicates in ```work_history```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:40:25.430922Z",
     "start_time": "2024-11-24T18:40:25.409781Z"
    }
   },
   "source": [
    "work_history = work_history.drop(columns=[\"Sequence\"]).drop_duplicates()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:41:21.298219Z",
     "start_time": "2024-11-24T18:41:21.039198Z"
    }
   },
   "source": [
    "word_history_tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=1, max_features=50, stop_words='english')\n",
    "word_history_tf_matrix = word_history_tf.fit_transform(work_history.groupby(\"UserID\").JobTitle.sum().values)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deal with the user set and the job set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:41:23.757670Z",
     "start_time": "2024-11-24T18:41:23.752177Z"
    }
   },
   "source": [
    "user_set = user_set.drop(columns=[\"Country\",\"ZipCode\",\"Major\",\"GraduationDate\",\"WindowID\"])"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ```user_set``` \n",
    "- label encoding for ```DegreeType```\n",
    "- one-hot encoding for ```State```\n",
    "- binary labels for Currently ```Employed/ManagedOthers```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:41:25.959690Z",
     "start_time": "2024-11-24T18:41:25.942213Z"
    }
   },
   "source": [
    "# user_set = pd.get_dummies(user_set, columns=[\"State\"])\n",
    "user_set.replace({\"CurrentlyEmployed\":{\"Yes\":1,\"No\":0}}, inplace=True)\n",
    "user_set.replace({\"ManagedOthers\":{\"Yes\":1,\"No\":0}}, inplace=True)\n",
    "user_set.replace({\"DegreeType\":{\"None\":0,\"High School\":1, \"Vocational\":2, \"Associate's\":3, \"Bachelor's\":4, \"Master's\":5, \"PhD\":6}}, \n",
    "                 inplace=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/38/xlfphpn930qcty0ghdcwlsfr0000gn/T/ipykernel_4827/347667782.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  user_set.replace({\"CurrentlyEmployed\":{\"Yes\":1,\"No\":0}}, inplace=True)\n",
      "/var/folders/38/xlfphpn930qcty0ghdcwlsfr0000gn/T/ipykernel_4827/347667782.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  user_set.replace({\"ManagedOthers\":{\"Yes\":1,\"No\":0}}, inplace=True)\n",
      "/var/folders/38/xlfphpn930qcty0ghdcwlsfr0000gn/T/ipykernel_4827/347667782.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  user_set.replace({\"DegreeType\":{\"None\":0,\"High School\":1, \"Vocational\":2, \"Associate's\":3, \"Bachelor's\":4, \"Master's\":5, \"PhD\":6}},\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:41:39.869295Z",
     "start_time": "2024-11-24T18:41:39.860366Z"
    }
   },
   "source": [
    "user_set"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        UserID  Split           City State  DegreeType  WorkHistoryCount  \\\n",
       "0           13   Test   Philadelphia    PA         4.0                 6   \n",
       "1           64  Train       Columbus    OH         5.0                 3   \n",
       "2          101  Train          Brick    NJ         1.0                 1   \n",
       "3          133  Train     Wilmington    DE         4.0                 6   \n",
       "4          182  Train         Lenexa    KS         1.0                 3   \n",
       "...        ...    ...            ...   ...         ...               ...   \n",
       "18741  1471625  Train   Indianapolis    IN         4.0                 4   \n",
       "18742  1471661  Train  Shartlesville    PA         4.0                 1   \n",
       "18743  1471838  Train         Peoria    AZ         5.0                 3   \n",
       "18744  1471948  Train       Glendale    AZ         1.0                 4   \n",
       "18745  1472019  Train       Erlanger    KY         1.0                 1   \n",
       "\n",
       "       TotalYearsExperience  CurrentlyEmployed  ManagedOthers  ManagedHowMany  \n",
       "0                       5.0                  1              0               0  \n",
       "1                      22.0                  1              0               0  \n",
       "2                       2.0                  0              1               4  \n",
       "3                       9.0                  1              1               6  \n",
       "4                       5.0                  1              1              10  \n",
       "...                     ...                ...            ...             ...  \n",
       "18741                   4.0                  1              1              10  \n",
       "18742                   3.0                  0              0               0  \n",
       "18743                   8.0                  1              0               0  \n",
       "18744                   6.0                  0              0               0  \n",
       "18745                   4.0                  0              0               0  \n",
       "\n",
       "[18746 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Split</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>DegreeType</th>\n",
       "      <th>WorkHistoryCount</th>\n",
       "      <th>TotalYearsExperience</th>\n",
       "      <th>CurrentlyEmployed</th>\n",
       "      <th>ManagedOthers</th>\n",
       "      <th>ManagedHowMany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Test</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>Train</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>OH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Train</td>\n",
       "      <td>Brick</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133</td>\n",
       "      <td>Train</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>DE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182</td>\n",
       "      <td>Train</td>\n",
       "      <td>Lenexa</td>\n",
       "      <td>KS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18741</th>\n",
       "      <td>1471625</td>\n",
       "      <td>Train</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18742</th>\n",
       "      <td>1471661</td>\n",
       "      <td>Train</td>\n",
       "      <td>Shartlesville</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18743</th>\n",
       "      <td>1471838</td>\n",
       "      <td>Train</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18744</th>\n",
       "      <td>1471948</td>\n",
       "      <td>Train</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18745</th>\n",
       "      <td>1472019</td>\n",
       "      <td>Train</td>\n",
       "      <td>Erlanger</td>\n",
       "      <td>KY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18746 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add binary labels into the dataset, indicating that whether the user and job are in the same city/state."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:42:24.612872Z",
     "start_time": "2024-11-24T18:41:44.355512Z"
    }
   },
   "source": [
    "city = []\n",
    "state = []\n",
    "groups = dataset.groupby(\"UserID\")\n",
    "for idx, group in tqdm(groups):\n",
    "    user_city = user_set[user_set.UserID==idx][\"City\"].values\n",
    "    user_state = user_set[user_set.UserID==idx][\"State\"].values\n",
    "    job_id_list = group.JobID.values\n",
    "    job_city = job_set[job_set.JobID.isin(job_id_list)][\"City\"].values\n",
    "    job_state = job_set[job_set.JobID.isin(job_id_list)][\"State\"].values\n",
    "    city.extend([0 if i!=user_city else 1 for i in job_city])\n",
    "    state.extend([0 if i!=user_state else 1 for i in job_state])\n",
    "dataset[\"City\"] = city\n",
    "dataset[\"State\"] = state"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18746/18746 [00:40<00:00, 467.19it/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:42:26.804098Z",
     "start_time": "2024-11-24T18:42:26.683431Z"
    }
   },
   "source": [
    "user_set.to_csv(\"user_set_cleaned.csv\", index=False)\n",
    "dataset.to_csv(\"dataset_cleaned.csv\", index=False)\n",
    "work_history.to_csv(\"work_history_cleaned.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build the training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:42:28.493526Z",
     "start_time": "2024-11-24T18:42:28.483446Z"
    }
   },
   "source": [
    "train_user = user_set[user_set.Split==\"Train\"].UserID.values\n",
    "test_user = user_set[user_set.Split==\"Test\"].UserID.values\n",
    "train_data = dataset[dataset.UserID.isin(train_user)]\n",
    "test_data = dataset[dataset.UserID.isin(test_user)]"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:44:16.501116Z",
     "start_time": "2024-11-24T18:42:29.912595Z"
    }
   },
   "source": [
    "groups = train_data.groupby(\"UserID\")\n",
    "X_train = np.zeros((1,158))\n",
    "Y_train = []\n",
    "for u_id, group in tqdm(groups):\n",
    "    user = user_set[user_set.UserID==u_id][[\"DegreeType\", \"WorkHistoryCount\", \"TotalYearsExperience\", \"CurrentlyEmployed\", \"ManagedOthers\", \"ManagedHowMany\"]]\n",
    "    u_idx = user.index.values[0]\n",
    "    user_feature = np.concatenate((user.values, word_history_tf_matrix[u_idx,:].toarray()),axis=1)\n",
    "    job_id_list = group.JobID.values\n",
    "    jobs = job_set[job_set.JobID.isin(job_id_list)]\n",
    "    j_idx = jobs.index.values\n",
    "    f = []\n",
    "    for i in j_idx:\n",
    "        feature = np.concatenate((user_feature, tfidf_matrix[i,:].toarray()), axis=1).reshape(156,).tolist()\n",
    "        f.append(feature)\n",
    "    feature = np.concatenate((group[[\"City\",\"State\"]].values, np.array(f)),axis=1)\n",
    "    X_train = np.concatenate((X_train, feature), axis=0)\n",
    "    Y_train.extend(group.label.values.tolist())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18486/18486 [01:46<00:00, 173.56it/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:44:20.480261Z",
     "start_time": "2024-11-24T18:44:20.476998Z"
    }
   },
   "source": [
    "X_train.shape, len(Y_train)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70669, 158), 70668)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:44:22.562826Z",
     "start_time": "2024-11-24T18:44:22.134826Z"
    }
   },
   "source": [
    "groups = test_data.groupby(\"UserID\")\n",
    "X_test = np.zeros((1,158))\n",
    "Y_test = []\n",
    "for u_id, group in tqdm(groups):\n",
    "    user = user_set[user_set.UserID==u_id][[\"DegreeType\", \"WorkHistoryCount\", \"TotalYearsExperience\", \"CurrentlyEmployed\", \"ManagedOthers\", \"ManagedHowMany\"]]\n",
    "    u_idx = user.index.values[0]\n",
    "    user_feature = np.concatenate((user.values, word_history_tf_matrix[u_idx,:].toarray()),axis=1)\n",
    "    job_id_list = group.JobID.values\n",
    "    jobs = job_set[job_set.JobID.isin(job_id_list)]\n",
    "    j_idx = jobs.index.values\n",
    "    f = []\n",
    "    for i in j_idx:\n",
    "        feature = np.concatenate((user_feature, tfidf_matrix[i,:].toarray()), axis=1).reshape(156,).tolist()\n",
    "        f.append(feature)\n",
    "    feature = np.concatenate((group[[\"City\",\"State\"]].values, np.array(f)),axis=1)\n",
    "    X_test = np.concatenate((X_test, feature), axis=0)\n",
    "    Y_test.extend(group.label.values.tolist())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:00<00:00, 635.55it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:44:26.830726Z",
     "start_time": "2024-11-24T18:44:26.827397Z"
    }
   },
   "source": [
    "X_test.shape, len(Y_test)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1055, 158), 1054)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:44:29.503794Z",
     "start_time": "2024-11-24T18:44:29.477003Z"
    }
   },
   "source": [
    "np.save(\"X_train.npy\",X_train[1:,])\n",
    "np.save(\"Y_train.npy\",np.array(Y_train))\n",
    "np.save(\"X_test.npy\",X_test[1:,])\n",
    "np.save(\"Y_test.npy\",np.array(Y_test))"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Construct models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:44:32.051986Z",
     "start_time": "2024-11-24T18:44:31.856785Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:44:33.496970Z",
     "start_time": "2024-11-24T18:44:33.492567Z"
    }
   },
   "source": [
    "def show_result(y_true, y_prediction):\n",
    "    report = classification_report(y_true,y_prediction,digits=4)\n",
    "    report = report.splitlines()\n",
    "    columns = ['class'] + report[0].split()\n",
    "    col_1, col_2, col_3, col_4, col_5 = [], [], [], [], []\n",
    "    for row in report[1:]:\n",
    "        if len(row.split()) != 0:\n",
    "            row = row.split()\n",
    "            if len(row) < 5:\n",
    "                col_1.append(row[0])\n",
    "                col_2.append('')\n",
    "                col_3.append('')\n",
    "                col_4.append(row[1])\n",
    "                col_5.append(row[2])\n",
    "            elif len(row) > 5:\n",
    "                col_1.append(row[0] + ' ' + row[1])\n",
    "                col_2.append(row[2])\n",
    "                col_3.append(row[3])\n",
    "                col_4.append(row[4])\n",
    "                col_5.append(row[5])\n",
    "            else:\n",
    "                col_1.append(row[0])\n",
    "                col_2.append(row[1])\n",
    "                col_3.append(row[2])\n",
    "                col_4.append(row[3])\n",
    "                col_5.append(row[4])\n",
    "    col_1.append(\"overall\")\n",
    "    col_2.append(precision_score(y_true, y_prediction))\n",
    "    col_3.append(recall_score(y_true, y_prediction))\n",
    "    col_4.append(f1_score(y_true, y_prediction))\n",
    "    col_5.append(roc_auc_score(y_true, y_prediction))\n",
    "    result = pd.DataFrame()\n",
    "    result[columns[0]] = col_1\n",
    "    result[columns[1]] = col_2\n",
    "    result[columns[2]] = col_3\n",
    "    result[columns[3]] = col_4\n",
    "    result[columns[4]] = col_5\n",
    "    print(\"——————Test——————\")\n",
    "    print(result)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:48:29.545130Z",
     "start_time": "2024-11-24T18:48:29.515937Z"
    }
   },
   "source": [
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "Y_train = np.load(\"Y_train.npy\")\n",
    "Y_test = np.load(\"Y_test.npy\")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:51:38.343472Z",
     "start_time": "2024-11-24T18:51:38.273416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values in X_train and X_test\n",
    "imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent', etc.\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:51:41.107723Z",
     "start_time": "2024-11-24T18:51:40.686543Z"
    }
   },
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred = [0 if i<0.5 else 1 for i in y_pred]\n",
    "show_result(Y_test, y_pred)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————Test——————\n",
      "          class precision    recall  f1-score  support\n",
      "0             0    0.5156    0.5028    0.5091      527\n",
      "1             1    0.5148    0.5275    0.5211      527\n",
      "2      accuracy                        0.5152     1054\n",
      "3     macro avg    0.5152    0.5152    0.5151     1054\n",
      "4  weighted avg    0.5152    0.5152    0.5151     1054\n",
      "5       overall  0.514815  0.527514  0.521087  0.51518\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:51:47.607254Z",
     "start_time": "2024-11-24T18:51:43.535603Z"
    }
   },
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, Y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————Test——————\n",
      "          class precision    recall  f1-score   support\n",
      "0             0    0.5184    0.5085    0.5134       527\n",
      "1             1    0.5177    0.5275    0.5226       527\n",
      "2      accuracy                        0.5180      1054\n",
      "3     macro avg    0.5180    0.5180    0.5180      1054\n",
      "4  weighted avg    0.5180    0.5180    0.5180      1054\n",
      "5       overall  0.517691  0.527514  0.522556  0.518027\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:51:50.452092Z",
     "start_time": "2024-11-24T18:51:50.364824Z"
    }
   },
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, Y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————Test——————\n",
      "          class precision    recall  f1-score  support\n",
      "0             0    0.5218    0.5446    0.5330      527\n",
      "1             1    0.5238    0.5009    0.5121      527\n",
      "2      accuracy                        0.5228     1054\n",
      "3     macro avg    0.5228    0.5228    0.5225     1054\n",
      "4  weighted avg    0.5228    0.5228    0.5225     1054\n",
      "5       overall   0.52381  0.500949  0.512124  0.52277\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:51:57.259918Z",
     "start_time": "2024-11-24T18:51:52.729268Z"
    }
   },
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, Y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————Test——————\n",
      "          class precision    recall  f1-score   support\n",
      "0             0    0.6152    0.5977    0.6064       527\n",
      "1             1    0.6089    0.6262    0.6174       527\n",
      "2      accuracy                        0.6120      1054\n",
      "3     macro avg    0.6120    0.6120    0.6119      1054\n",
      "4  weighted avg    0.6120    0.6120    0.6119      1054\n",
      "5       overall  0.608856  0.626186  0.617399  0.611954\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T18:52:26.469836Z",
     "start_time": "2024-11-24T18:51:59.515159Z"
    }
   },
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————Test——————\n",
      "          class precision    recall  f1-score   support\n",
      "0             0    0.6408    0.6262    0.6334       527\n",
      "1             1    0.6345    0.6490    0.6417       527\n",
      "2      accuracy                        0.6376      1054\n",
      "3     macro avg    0.6376    0.6376    0.6375      1054\n",
      "4  weighted avg    0.6376    0.6376    0.6375      1054\n",
      "5       overall  0.634508  0.648956  0.641651  0.637571\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
