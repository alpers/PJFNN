{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "- TF-IDF vectors to represent the texts.\n",
    "- Use several machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_set = pd.read_csv(\"user_set.csv\")\n",
    "job_set = pd.read_csv(\"job_set_cleaned.csv\")\n",
    "work_history = pd.read_csv(\"work_history.csv\")\n",
    "dataset = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TF-IDF vectors for text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 1 min\n",
    "job_set = job_set.fillna(\" \")\n",
    "job_set[\"word\"] = job_set.Title + job_set.Description + job_set.Requirements\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=5, max_features=100, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(job_set['word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Filter out users with more than 10 applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6766"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = sorted(dict(dataset.UserID.value_counts()).items(), key=lambda x: x[1], reverse=True)\n",
    "exclude_user_id = [i[0] for i in temp if i [1]>=10]\n",
    "len(exclude_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset.UserID.isin(exclude_user_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select data in ```work_history,user_set```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = dataset.UserID.unique()\n",
    "work_history = work_history[work_history.UserID.isin(user_id)]\n",
    "user_set = user_set[user_set.UserID.isin(user_id)]\n",
    "user_set.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop duplicates in ```work_history```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_history = work_history.drop(columns=[\"Sequence\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_history_tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, max_features=50, stop_words='english')\n",
    "word_history_tf_matrix = word_history_tf.fit_transform(work_history.groupby(\"UserID\").JobTitle.sum().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deal with the user set and the job set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_set = user_set.drop(columns=[\"Country\",\"ZipCode\",\"Major\",\"GraduationDate\",\"WindowID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ```user_set``` \n",
    "- label encoding for ```DegreeType```\n",
    "- one-hot encoding for ```State```\n",
    "- binary labels for Currently ```Employed/ManagedOthers```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_set = pd.get_dummies(user_set, columns=[\"State\"])\n",
    "user_set.replace({\"CurrentlyEmployed\":{\"Yes\":1,\"No\":0}}, inplace=True)\n",
    "user_set.replace({\"ManagedOthers\":{\"Yes\":1,\"No\":0}}, inplace=True)\n",
    "user_set.replace({\"DegreeType\":{\"None\":0,\"High School\":1, \"Vocational\":2, \"Associate's\":3, \"Bachelor's\":4, \"Master's\":5, \"PhD\":6}}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Split</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>DegreeType</th>\n",
       "      <th>WorkHistoryCount</th>\n",
       "      <th>TotalYearsExperience</th>\n",
       "      <th>CurrentlyEmployed</th>\n",
       "      <th>ManagedOthers</th>\n",
       "      <th>ManagedHowMany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>Test</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>Train</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>OH</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Train</td>\n",
       "      <td>Brick</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133</td>\n",
       "      <td>Train</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>DE</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182</td>\n",
       "      <td>Train</td>\n",
       "      <td>Lenexa</td>\n",
       "      <td>KS</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18745</th>\n",
       "      <td>1471625</td>\n",
       "      <td>Train</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18746</th>\n",
       "      <td>1471661</td>\n",
       "      <td>Train</td>\n",
       "      <td>Shartlesville</td>\n",
       "      <td>PA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18747</th>\n",
       "      <td>1471838</td>\n",
       "      <td>Train</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18748</th>\n",
       "      <td>1471948</td>\n",
       "      <td>Train</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18749</th>\n",
       "      <td>1472019</td>\n",
       "      <td>Train</td>\n",
       "      <td>Erlanger</td>\n",
       "      <td>KY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18750 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID  Split           City State  DegreeType  WorkHistoryCount  \\\n",
       "0           13   Test   Philadelphia    PA           4                 6   \n",
       "1           64  Train       Columbus    OH           5                 3   \n",
       "2          101  Train          Brick    NJ           1                 1   \n",
       "3          133  Train     Wilmington    DE           4                 6   \n",
       "4          182  Train         Lenexa    KS           1                 3   \n",
       "...        ...    ...            ...   ...         ...               ...   \n",
       "18745  1471625  Train   Indianapolis    IN           4                 4   \n",
       "18746  1471661  Train  Shartlesville    PA           4                 1   \n",
       "18747  1471838  Train         Peoria    AZ           5                 3   \n",
       "18748  1471948  Train       Glendale    AZ           1                 4   \n",
       "18749  1472019  Train       Erlanger    KY           1                 1   \n",
       "\n",
       "       TotalYearsExperience  CurrentlyEmployed  ManagedOthers  ManagedHowMany  \n",
       "0                       5.0                  1              0               0  \n",
       "1                      22.0                  1              0               0  \n",
       "2                       2.0                  0              1               4  \n",
       "3                       9.0                  1              1               6  \n",
       "4                       5.0                  1              1              10  \n",
       "...                     ...                ...            ...             ...  \n",
       "18745                   4.0                  1              1              10  \n",
       "18746                   3.0                  0              0               0  \n",
       "18747                   8.0                  1              0               0  \n",
       "18748                   6.0                  0              0               0  \n",
       "18749                   4.0                  0              0               0  \n",
       "\n",
       "[18750 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add binary labels into the dataset, indicating that whether the user and job are in the same city/state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18750/18750 [01:43<00:00, 181.29it/s]\n"
     ]
    }
   ],
   "source": [
    "city = []\n",
    "state = []\n",
    "groups = dataset.groupby(\"UserID\")\n",
    "for idx, group in tqdm(groups):\n",
    "    user_city = user_set[user_set.UserID==idx][\"City\"].values\n",
    "    user_state = user_set[user_set.UserID==idx][\"State\"].values\n",
    "    job_id_list = group.JobID.values\n",
    "    job_city = job_set[job_set.JobID.isin(job_id_list)][\"City\"].values\n",
    "    job_state = job_set[job_set.JobID.isin(job_id_list)][\"State\"].values\n",
    "    city.extend([0 if i!=user_city else 1 for i in job_city])\n",
    "    state.extend([0 if i!=user_state else 1 for i in job_state])\n",
    "dataset[\"City\"] = city\n",
    "dataset[\"State\"] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_set.to_csv(\"user_set_cleaned.csv\", index=False)\n",
    "dataset.to_csv(\"dataset_cleaned.csv\", index=False)\n",
    "work_history.to_csv(\"work_history_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build the training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = user_set[user_set.Split==\"Train\"].UserID.values\n",
    "test_user = user_set[user_set.Split==\"Test\"].UserID.values\n",
    "train_data = dataset[dataset.UserID.isin(train_user)]\n",
    "test_data = dataset[dataset.UserID.isin(test_user)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18490/18490 [11:54<00:00, 25.86it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = train_data.groupby(\"UserID\")\n",
    "X_train = np.zeros((1,158))\n",
    "Y_train = []\n",
    "for u_id, group in tqdm(groups):\n",
    "    user = user_set[user_set.UserID==u_id][[\"DegreeType\", \"WorkHistoryCount\", \"TotalYearsExperience\", \"CurrentlyEmployed\", \n",
    "                                            \"ManagedOthers\", \"ManagedHowMany\"]]\n",
    "    u_idx = user.index.values[0]\n",
    "    user_feature = np.concatenate((user.values, word_history_tf_matrix[u_idx,:].toarray()),axis=1)\n",
    "    job_id_list = group.JobID.values\n",
    "    jobs = job_set[job_set.JobID.isin(job_id_list)]\n",
    "    j_idx = jobs.index.values\n",
    "    f = []\n",
    "    for i in j_idx:\n",
    "        feature = np.concatenate((user_feature, tfidf_matrix[i,:].toarray()), axis=1).reshape(156,).tolist()\n",
    "        f.append(feature)\n",
    "    feature = np.concatenate((group[[\"City\",\"State\"]].values, np.array(f)),axis=1)\n",
    "    X_train = np.concatenate((X_train, feature), axis=0)\n",
    "    Y_train.extend(group.label.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70681, 158), 70680)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:01<00:00, 177.88it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = test_data.groupby(\"UserID\")\n",
    "X_test = np.zeros((1,158))\n",
    "Y_test = []\n",
    "for u_id, group in tqdm(groups):\n",
    "    user = user_set[user_set.UserID==u_id][[\"DegreeType\", \"WorkHistoryCount\", \"TotalYearsExperience\", \"CurrentlyEmployed\", \n",
    "                                            \"ManagedOthers\", \"ManagedHowMany\"]]\n",
    "    u_idx = user.index.values[0]\n",
    "    user_feature = np.concatenate((user.values, word_history_tf_matrix[u_idx,:].toarray()),axis=1)\n",
    "    job_id_list = group.JobID.values\n",
    "    jobs = job_set[job_set.JobID.isin(job_id_list)]\n",
    "    j_idx = jobs.index.values\n",
    "    f = []\n",
    "    for i in j_idx:\n",
    "        feature = np.concatenate((user_feature, tfidf_matrix[i,:].toarray()), axis=1).reshape(156,).tolist()\n",
    "        f.append(feature)\n",
    "    feature = np.concatenate((group[[\"City\",\"State\"]].values, np.array(f)),axis=1)\n",
    "    X_test = np.concatenate((X_test, feature), axis=0)\n",
    "    Y_test.extend(group.label.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1055, 158), 1054)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train.npy\",X_train[1:,])\n",
    "np.save(\"Y_train.npy\",np.array(Y_train))\n",
    "np.save(\"X_test.npy\",X_test[1:,])\n",
    "np.save(\"Y_test.npy\",np.array(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Construct models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(y_true, y_prediction):\n",
    "    report = classification_report(y_true,y_prediction,digits=4)\n",
    "    report = report.splitlines()\n",
    "    columns = ['class'] + report[0].split()\n",
    "    col_1, col_2, col_3, col_4, col_5 = [], [], [], [], []\n",
    "    for row in report[1:]:\n",
    "        if len(row.split()) != 0:\n",
    "            row = row.split()\n",
    "            if len(row) < 5:\n",
    "                col_1.append(row[0])\n",
    "                col_2.append('')\n",
    "                col_3.append('')\n",
    "                col_4.append(row[1])\n",
    "                col_5.append(row[2])\n",
    "            elif len(row) > 5:\n",
    "                col_1.append(row[0] + ' ' + row[1])\n",
    "                col_2.append(row[2])\n",
    "                col_3.append(row[3])\n",
    "                col_4.append(row[4])\n",
    "                col_5.append(row[5])\n",
    "            else:\n",
    "                col_1.append(row[0])\n",
    "                col_2.append(row[1])\n",
    "                col_3.append(row[2])\n",
    "                col_4.append(row[3])\n",
    "                col_5.append(row[4])\n",
    "    col_1.append(\"overall\")\n",
    "    col_2.append(precision_score(y_true, y_prediction))\n",
    "    col_3.append(recall_score(y_true, y_prediction))\n",
    "    col_4.append(f1_score(y_true, y_prediction))\n",
    "    col_5.append(roc_auc_score(y_true, y_prediction))\n",
    "    result = pd.DataFrame()\n",
    "    result[columns[0]] = col_1\n",
    "    result[columns[1]] = col_2\n",
    "    result[columns[2]] = col_3\n",
    "    result[columns[3]] = col_4\n",
    "    result[columns[4]] = col_5\n",
    "    print(\"â€”â€”â€”â€”â€”â€”Testâ€”â€”â€”â€”â€”â€”\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "Y_train = np.load(\"Y_train.npy\")\n",
    "Y_texs = np.load(\"Y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€”â€”â€”â€”â€”â€”Testâ€”â€”â€”â€”â€”â€”\n",
      "          class precision    recall  f1-score   support\n",
      "0             0    0.5418    0.5655    0.5534       527\n",
      "1             1    0.5456    0.5218    0.5335       527\n",
      "2      accuracy                        0.5436      1054\n",
      "3     macro avg    0.5437    0.5436    0.5434      1054\n",
      "4  weighted avg    0.5437    0.5436    0.5434      1054\n",
      "5       overall  0.545635  0.521822  0.533463  0.543643\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred = [0 if i<0.5 else 1 for i in y_pred]\n",
    "show_result(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€”â€”â€”â€”â€”â€”Testâ€”â€”â€”â€”â€”â€”\n",
      "          class precision    recall  f1-score   support\n",
      "0             0    0.5381    0.5769    0.5568       527\n",
      "1             1    0.5440    0.5047    0.5236       527\n",
      "2      accuracy                        0.5408      1054\n",
      "3     macro avg    0.5410    0.5408    0.5402      1054\n",
      "4  weighted avg    0.5410    0.5408    0.5402      1054\n",
      "5       overall  0.543967  0.504744  0.523622  0.540797\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, Y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€”â€”â€”â€”â€”â€”Testâ€”â€”â€”â€”â€”â€”\n",
      "          class precision   recall  f1-score   support\n",
      "0             0    0.5125   0.5825    0.5453       527\n",
      "1             1    0.5165   0.4459    0.4786       527\n",
      "2      accuracy                       0.5142      1054\n",
      "3     macro avg    0.5145   0.5142    0.5120      1054\n",
      "4  weighted avg    0.5145   0.5142    0.5120      1054\n",
      "5       overall  0.516484  0.44592  0.478615  0.514231\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, Y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€”â€”â€”â€”â€”â€”Testâ€”â€”â€”â€”â€”â€”\n",
      "          class precision    recall  f1-score   support\n",
      "0             0    0.6211    0.6471    0.6338       527\n",
      "1             1    0.6317    0.6053    0.6182       527\n",
      "2      accuracy                        0.6262      1054\n",
      "3     macro avg    0.6264    0.6262    0.6260      1054\n",
      "4  weighted avg    0.6264    0.6262    0.6260      1054\n",
      "5       overall  0.631683  0.605313  0.618217  0.626186\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, Y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€”â€”â€”â€”â€”â€”Testâ€”â€”â€”â€”â€”â€”\n",
      "          class precision    recall  f1-score   support\n",
      "0             0    0.6609    0.6509    0.6558       527\n",
      "1             1    0.6561    0.6660    0.6610       527\n",
      "2      accuracy                        0.6584      1054\n",
      "3     macro avg    0.6585    0.6584    0.6584      1054\n",
      "4  weighted avg    0.6585    0.6584    0.6584      1054\n",
      "5       overall  0.656075  0.666034  0.661017  0.658444\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "show_result(Y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
